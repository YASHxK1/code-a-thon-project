{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YASHxK1/code-a-thon-project/blob/main/this%20file.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEd4DnYt0d8i"
      },
      "source": [
        "using this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ltx8smzPn6s2"
      },
      "outputs": [],
      "source": [
        "    # Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout, LayerNormalization, MultiHeadAttention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "58v3_DRi0d8n"
      },
      "outputs": [],
      "source": [
        "# Create a sample dataset (you can replace this with your own dataset)\n",
        "def create_sample_dataset():\n",
        "    conversations = [\n",
        "        (\"I've been feeling really down lately\", \"I understand you're going through a difficult time. Can you tell me more about what's been happening?\"),\n",
        "        (\"I can't sleep at night\", \"Sleep difficulties can be really challenging. Have you noticed any patterns in your sleep disturbance?\"),\n",
        "        (\"I'm constantly worried about everything\", \"It sounds like you're experiencing anxiety. Let's explore what specific situations trigger these worries.\"),\n",
        "        (\"I feel overwhelmed with work\", \"Managing work stress can be difficult. What aspects of your work are causing the most pressure?\"),\n",
        "        (\"I keep having panic attacks\", \"That must be very distressing. Can you describe what happens during these panic attacks?\"),\n",
        "        (\"I feel lonely all the time\", \"Feeling lonely can be very painful. What kind of social connections do you currently have?\"),\n",
        "        (\"I'm having relationship problems\", \"Relationship challenges can be complex. Could you share more about what's happening?\"),\n",
        "        (\"I feel worthless\", \"I hear that you're struggling with self-worth. What experiences have contributed to these feelings?\"),\n",
        "        (\"I can't focus on anything\", \"Concentration difficulties can be frustrating. When did you first notice these changes?\"),\n",
        "        (\"I'm grieving the loss of a loved one\", \"I'm so sorry for your loss. Would you like to tell me about your loved one?\")\n",
        "    ]\n",
        "    # Multiply the dataset to create more training examples\n",
        "    expanded_conversations = conversations * 50  # This will create 500 conversation pairs\n",
        "    return expanded_conversations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Tk7VvRgB0d8o"
      },
      "outputs": [],
      "source": [
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s\\?]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Data preparation class\n",
        "class DataPreparator:\n",
        "    def __init__(self, max_sequence_length=50):\n",
        "        self.tokenizer = None\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "\n",
        "    def prepare_data(self, conversations):\n",
        "        # Split conversations into questions and answers\n",
        "        questions, answers = zip(*conversations)\n",
        "\n",
        "        # Preprocess texts\n",
        "        questions = [preprocess_text(q) for q in questions]\n",
        "        answers = [preprocess_text(a) for a in answers]\n",
        "\n",
        "        # Add start and end tokens to answers\n",
        "        answers = [f'<start> {a} <end>' for a in answers]\n",
        "\n",
        "        # Create and fit tokenizer\n",
        "        self.tokenizer = Tokenizer(filters='')\n",
        "        self.tokenizer.fit_on_texts(questions + answers)\n",
        "\n",
        "        # Convert texts to sequences\n",
        "        encoder_input_data = self.tokenizer.texts_to_sequences(questions)\n",
        "        decoder_input_data = self.tokenizer.texts_to_sequences(answers)\n",
        "\n",
        "        # Pad sequences\n",
        "        encoder_input_data = pad_sequences(encoder_input_data, maxlen=self.max_sequence_length, padding='post')\n",
        "        decoder_input_data = pad_sequences(decoder_input_data, maxlen=self.max_sequence_length, padding='post')\n",
        "\n",
        "        # Create decoder output data (shifted by one position)\n",
        "        decoder_output_data = np.zeros_like(decoder_input_data)\n",
        "        decoder_output_data[:, :-1] = decoder_input_data[:, 1:]\n",
        "\n",
        "        return encoder_input_data, decoder_input_data, decoder_output_data\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.tokenizer.word_index) + 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "edzycO6d0d8o"
      },
      "outputs": [],
      "source": [
        "# Mental Health Consultation Model\n",
        "class MentalHealthLLM:\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim=256, lstm_units=256):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm_units = lstm_units\n",
        "        self.encoder_model = None\n",
        "        self.decoder_model = None\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        # Encoder\n",
        "        encoder_inputs = Input(shape=(self.max_sequence_length,))\n",
        "        encoder_embedding = Embedding(self.vocab_size, self.embedding_dim)(encoder_inputs)\n",
        "        encoder_lstm = LSTM(self.lstm_units, return_state=True, return_sequences=True)\n",
        "        encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "        encoder_states = [state_h, state_c]\n",
        "\n",
        "        # Add self-attention to encoder\n",
        "        attention = MultiHeadAttention(num_heads=8, key_dim=32)\n",
        "        attention_output = attention(encoder_outputs, encoder_outputs)\n",
        "        encoder_outputs = LayerNormalization()(attention_output + encoder_outputs)\n",
        "\n",
        "        # Decoder\n",
        "        decoder_inputs = Input(shape=(self.max_sequence_length,))\n",
        "        decoder_embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "        decoder_lstm = LSTM(self.lstm_units, return_sequences=True, return_state=True)\n",
        "\n",
        "        # Connect decoder to encoder\n",
        "        decoder_embedded = decoder_embedding(decoder_inputs)\n",
        "        decoder_outputs, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states)\n",
        "\n",
        "        # Add attention between encoder and decoder\n",
        "        attention = MultiHeadAttention(num_heads=8, key_dim=32)\n",
        "        attention_output = attention(decoder_outputs, encoder_outputs)\n",
        "        decoder_outputs = LayerNormalization()(attention_output + decoder_outputs)\n",
        "\n",
        "        # Add dropout for regularization\n",
        "        decoder_outputs = Dropout(0.5)(decoder_outputs)\n",
        "        decoder_dense = Dense(self.vocab_size, activation='softmax')\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        # Create the full model\n",
        "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5VdWMMn60d8p"
      },
      "outputs": [],
      "source": [
        "# Mental Health Consultation Model\n",
        "class MentalHealthLLM:\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim=256, lstm_units=256):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm_units = lstm_units\n",
        "        self.encoder_model = None\n",
        "        self.decoder_model = None\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        # Encoder\n",
        "        encoder_inputs = Input(shape=(self.max_sequence_length,))\n",
        "        encoder_embedding = Embedding(self.vocab_size, self.embedding_dim)(encoder_inputs)\n",
        "        encoder_lstm = LSTM(self.lstm_units, return_state=True, return_sequences=True)\n",
        "        encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "        encoder_states = [state_h, state_c]\n",
        "\n",
        "        # Add self-attention to encoder\n",
        "        attention = MultiHeadAttention(num_heads=8, key_dim=32)\n",
        "        attention_output = attention(encoder_outputs, encoder_outputs)\n",
        "        encoder_outputs = LayerNormalization()(attention_output + encoder_outputs)\n",
        "\n",
        "        # Decoder\n",
        "        decoder_inputs = Input(shape=(self.max_sequence_length,))\n",
        "        decoder_embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "        decoder_lstm = LSTM(self.lstm_units, return_sequences=True, return_state=True)\n",
        "\n",
        "        # Connect decoder to encoder\n",
        "        decoder_embedded = decoder_embedding(decoder_inputs)\n",
        "        decoder_outputs, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states)\n",
        "\n",
        "        # Add attention between encoder and decoder\n",
        "        attention = MultiHeadAttention(num_heads=8, key_dim=32)\n",
        "        attention_output = attention(decoder_outputs, encoder_outputs)\n",
        "        decoder_outputs = LayerNormalization()(attention_output + decoder_outputs)\n",
        "\n",
        "        # Add dropout for regularization\n",
        "        decoder_outputs = Dropout(0.5)(decoder_outputs)\n",
        "        decoder_dense = Dense(self.vocab_size, activation='softmax')\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        # Create the full model\n",
        "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Create inference models\n",
        "        self.encoder_model = Model(encoder_inputs, [encoder_outputs] + encoder_states)\n",
        "\n",
        "        decoder_state_input_h = Input(shape=(self.lstm_units,))\n",
        "        decoder_state_input_c = Input(shape=(self.lstm_units,))\n",
        "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "        decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "            decoder_embedded,\n",
        "            initial_state=decoder_states_inputs\n",
        "        )\n",
        "        decoder_states = [state_h, state_c]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "        self.decoder_model = Model(\n",
        "            [decoder_inputs] + decoder_states_inputs,\n",
        "            [decoder_outputs] + decoder_states\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train(self, encoder_input_data, decoder_input_data, decoder_output_data,\n",
        "              batch_size=32, epochs=100, validation_split=0.2): # Corrected indentation\n",
        "\n",
        "        # Implement early stopping and model checkpointing\n",
        "        callbacks = [\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=5,\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            ModelCheckpoint(\n",
        "                'best_model.h5',\n",
        "                monitor='val_loss',\n",
        "                save_best_only=True\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(\n",
        "            [encoder_input_data, decoder_input_data],\n",
        "            decoder_output_data,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_split=validation_split,\n",
        "            callbacks=callbacks\n",
        "        )\n",
        "\n",
        "        return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNhOnt6Z0d8q",
        "outputId": "fabf3d48-d104-41e2-95f9-589f48f61ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Mental Health LLM training...\n",
            "Creating dataset...\n",
            "Preparing data...\n",
            "Building and training model...\n",
            "Epoch 1/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - accuracy: 0.5119 - loss: 3.1147"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 876ms/step - accuracy: 0.5200 - loss: 3.0547 - val_accuracy: 0.6940 - val_loss: 1.4190\n",
            "Epoch 2/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625ms/step - accuracy: 0.6946 - loss: 1.5547"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 692ms/step - accuracy: 0.6952 - loss: 1.5497 - val_accuracy: 0.7420 - val_loss: 1.1366\n",
            "Epoch 3/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617ms/step - accuracy: 0.7241 - loss: 1.2469"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 683ms/step - accuracy: 0.7245 - loss: 1.2424 - val_accuracy: 0.7700 - val_loss: 0.8232\n",
            "Epoch 4/50\n",
            "\u001b[1m 2/13\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7541 - loss: 0.9955"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    print(\"Creating dataset...\")\n",
        "    conversations = create_sample_dataset()\n",
        "\n",
        "    print(\"Preparing data...\")\n",
        "    data_preparator = DataPreparator(max_sequence_length=50)\n",
        "    encoder_input_data, decoder_input_data, decoder_output_data = data_preparator.prepare_data(conversations)\n",
        "\n",
        "    print(\"Building and training model...\")\n",
        "    model = MentalHealthLLM(\n",
        "        vocab_size=data_preparator.vocab_size,\n",
        "        max_sequence_length=50,\n",
        "        embedding_dim=256,\n",
        "        lstm_units=256\n",
        "    )\n",
        "\n",
        "    history = model.train(\n",
        "        encoder_input_data,\n",
        "        decoder_input_data,\n",
        "        decoder_output_data,\n",
        "        batch_size=32,\n",
        "        epochs=50,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    print(\"\\nTesting the model with sample inputs...\")\n",
        "    test_inputs = [\n",
        "        \"I've been feeling really sad lately\",\n",
        "        \"I'm having trouble sleeping\",\n",
        "        \"I feel anxious all the time\"\n",
        "    ]\n",
        "\n",
        "    for test_input in test_inputs:\n",
        "        response = model.generate_response(test_input, data_preparator.tokenizer)\n",
        "        print(f\"\\nInput: {test_input}\")\n",
        "        print(f\"Response: {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Mental Health LLM training...\")\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "using this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928,
          "referenced_widgets": [
            "9701fe6fd7b74b51bfee42055a2d5098",
            "0f8150fb33874a928be3320b4bc8612b",
            "dc49e9a469684be7800ea543221ce22f",
            "ba6bab2622774c9da7fed24d4886a8a9",
            "645ddd6da38d4687914a06598b84b917",
            "69b51a6a317e4d10aff10e1c1e154134",
            "1278b93fbf9b43cf9eab317eb70ccd60",
            "c91d80f31ffa41f5864bfbcf9a0936b1",
            "b9fd4a6fe9e84b21b6dd2a060949d948",
            "59ccacd60ffb429ba840615b79e7c155",
            "b4e45d5a30a54fd99aa994a451da5851"
          ]
        },
        "id": "ltx8smzPn6s2",
        "outputId": "90670ab0-71fb-4488-d2f1-00391b6b0b85"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "    # Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout, LayerNormalization, MultiHeadAttention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a sample dataset (you can replace this with your own dataset)\n",
        "def create_sample_dataset():\n",
        "    conversations = [\n",
        "        (\"I've been feeling really down lately\", \"I understand you're going through a difficult time. Can you tell me more about what's been happening?\"),\n",
        "        (\"I can't sleep at night\", \"Sleep difficulties can be really challenging. Have you noticed any patterns in your sleep disturbance?\"),\n",
        "        (\"I'm constantly worried about everything\", \"It sounds like you're experiencing anxiety. Let's explore what specific situations trigger these worries.\"),\n",
        "        (\"I feel overwhelmed with work\", \"Managing work stress can be difficult. What aspects of your work are causing the most pressure?\"),\n",
        "        (\"I keep having panic attacks\", \"That must be very distressing. Can you describe what happens during these panic attacks?\"),\n",
        "        (\"I feel lonely all the time\", \"Feeling lonely can be very painful. What kind of social connections do you currently have?\"),\n",
        "        (\"I'm having relationship problems\", \"Relationship challenges can be complex. Could you share more about what's happening?\"),\n",
        "        (\"I feel worthless\", \"I hear that you're struggling with self-worth. What experiences have contributed to these feelings?\"),\n",
        "        (\"I can't focus on anything\", \"Concentration difficulties can be frustrating. When did you first notice these changes?\"),\n",
        "        (\"I'm grieving the loss of a loved one\", \"I'm so sorry for your loss. Would you like to tell me about your loved one?\")\n",
        "    ]\n",
        "    # Multiply the dataset to create more training examples\n",
        "    expanded_conversations = conversations * 50  # This will create 500 conversation pairs\n",
        "    return expanded_conversations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s\\?]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Data preparation class\n",
        "class DataPreparator:\n",
        "    def __init__(self, max_sequence_length=50):\n",
        "        self.tokenizer = None\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "\n",
        "    def prepare_data(self, conversations):\n",
        "        # Split conversations into questions and answers\n",
        "        questions, answers = zip(*conversations)\n",
        "\n",
        "        # Preprocess texts\n",
        "        questions = [preprocess_text(q) for q in questions]\n",
        "        answers = [preprocess_text(a) for a in answers]\n",
        "\n",
        "        # Add start and end tokens to answers\n",
        "        answers = [f'<start> {a} <end>' for a in answers]\n",
        "\n",
        "        # Create and fit tokenizer\n",
        "        self.tokenizer = Tokenizer(filters='')\n",
        "        self.tokenizer.fit_on_texts(questions + answers)\n",
        "\n",
        "        # Convert texts to sequences\n",
        "        encoder_input_data = self.tokenizer.texts_to_sequences(questions)\n",
        "        decoder_input_data = self.tokenizer.texts_to_sequences(answers)\n",
        "\n",
        "        # Pad sequences\n",
        "        encoder_input_data = pad_sequences(encoder_input_data, maxlen=self.max_sequence_length, padding='post')\n",
        "        decoder_input_data = pad_sequences(decoder_input_data, maxlen=self.max_sequence_length, padding='post')\n",
        "\n",
        "        # Create decoder output data (shifted by one position)\n",
        "        decoder_output_data = np.zeros_like(decoder_input_data)\n",
        "        decoder_output_data[:, :-1] = decoder_input_data[:, 1:]\n",
        "\n",
        "        return encoder_input_data, decoder_input_data, decoder_output_data\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.tokenizer.word_index) + 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mental Health Consultation Model\n",
        "class MentalHealthLLM:\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim=256, lstm_units=256):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm_units = lstm_units\n",
        "        self.encoder_model = None\n",
        "        self.decoder_model = None\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        # Encoder\n",
        "        encoder_inputs = Input(shape=(self.max_sequence_length,))\n",
        "        encoder_embedding = Embedding(self.vocab_size, self.embedding_dim)(encoder_inputs)\n",
        "        encoder_lstm = LSTM(self.lstm_units, return_state=True, return_sequences=True)\n",
        "        encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "        encoder_states = [state_h, state_c]\n",
        "\n",
        "        # Add self-attention to encoder\n",
        "        attention = MultiHeadAttention(num_heads=8, key_dim=32)\n",
        "        attention_output = attention(encoder_outputs, encoder_outputs)\n",
        "        encoder_outputs = LayerNormalization()(attention_output + encoder_outputs)\n",
        "\n",
        "        # Decoder\n",
        "        decoder_inputs = Input(shape=(self.max_sequence_length,))\n",
        "        decoder_embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "        decoder_lstm = LSTM(self.lstm_units, return_sequences=True, return_state=True)\n",
        "\n",
        "        # Connect decoder to encoder\n",
        "        decoder_embedded = decoder_embedding(decoder_inputs)\n",
        "        decoder_outputs, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states)\n",
        "\n",
        "        # Add attention between encoder and decoder\n",
        "        attention = MultiHeadAttention(num_heads=8, key_dim=32)\n",
        "        attention_output = attention(decoder_outputs, encoder_outputs)\n",
        "        decoder_outputs = LayerNormalization()(attention_output + decoder_outputs)\n",
        "\n",
        "        # Add dropout for regularization\n",
        "        decoder_outputs = Dropout(0.5)(decoder_outputs)\n",
        "        decoder_dense = Dense(self.vocab_size, activation='softmax')\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        # Create the full model\n",
        "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "        # Create inference models\n",
        "        self.encoder_model = Model(encoder_inputs, [encoder_outputs] + encoder_states)\n",
        "\n",
        "        decoder_state_input_h = Input(shape=(self.lstm_units,))\n",
        "        decoder_state_input_c = Input(shape=(self.lstm_units,))\n",
        "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "        decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "            decoder_embedded,\n",
        "            initial_state=decoder_states_inputs\n",
        "        )\n",
        "        decoder_states = [state_h, state_c]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "        self.decoder_model = Model(\n",
        "            [decoder_inputs] + decoder_states_inputs,\n",
        "            [decoder_outputs] + decoder_states\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train(self, encoder_input_data, decoder_input_data, decoder_output_data,\n",
        "              batch_size=32, epochs=100, validation_split=0.2):\n",
        "\n",
        "        # Implement early stopping and model checkpointing\n",
        "        callbacks = [\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=5,\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            ModelCheckpoint(\n",
        "                'best_model.h5',\n",
        "                monitor='val_loss',\n",
        "                save_best_only=True\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(\n",
        "            [encoder_input_data, decoder_input_data],\n",
        "            decoder_output_data,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_split=validation_split,\n",
        "            callbacks=callbacks\n",
        "        )\n",
        "\n",
        "        return history\n",
        "\n",
        "    def generate_response(self, input_text, tokenizer):\n",
        "        # Preprocess input text\n",
        "        input_text = preprocess_text(input_text)\n",
        "\n",
        "        # Convert input text to sequence\n",
        "        input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "        input_seq = pad_sequences(input_seq, maxlen=self.max_sequence_length, padding='post')\n",
        "\n",
        "        # Encode input sequence\n",
        "        [encoder_outputs, state_h, state_c] = self.encoder_model.predict(input_seq)\n",
        "\n",
        "        # Generate empty target sequence\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = tokenizer.word_index.get('<start>', 1)\n",
        "\n",
        "        # Generate response\n",
        "        decoded_sentence = []\n",
        "        max_length = self.max_sequence_length\n",
        "\n",
        "        while True:\n",
        "            output_tokens, h, c = self.decoder_model.predict(\n",
        "                [target_seq] + [state_h, state_c]\n",
        "            )\n",
        "\n",
        "            # Sample token with highest probability\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "            # Convert token to word\n",
        "            sampled_word = ''\n",
        "            for word, index in tokenizer.word_index.items():\n",
        "                if index == sampled_token_index:\n",
        "                    sampled_word = word\n",
        "                    break\n",
        "\n",
        "            # Break conditions\n",
        "            if sampled_word == '<end>' or len(decoded_sentence) > max_length:\n",
        "                break\n",
        "\n",
        "            decoded_sentence.append(sampled_word)\n",
        "\n",
        "            # Update target sequence\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "            # Update states\n",
        "            state_h, state_c = h, c\n",
        "\n",
        "        return ' '.join(decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    print(\"Creating dataset...\")\n",
        "    conversations = create_sample_dataset()\n",
        "\n",
        "    print(\"Preparing data...\")\n",
        "    data_preparator = DataPreparator(max_sequence_length=50)\n",
        "    encoder_input_data, decoder_input_data, decoder_output_data = data_preparator.prepare_data(conversations)\n",
        "\n",
        "    print(\"Building and training model...\")\n",
        "    model = MentalHealthLLM(\n",
        "        vocab_size=data_preparator.vocab_size,\n",
        "        max_sequence_length=50,\n",
        "        embedding_dim=256,\n",
        "        lstm_units=256\n",
        "    )\n",
        "\n",
        "    history = model.train(\n",
        "        encoder_input_data,\n",
        "        decoder_input_data,\n",
        "        decoder_output_data,\n",
        "        batch_size=32,\n",
        "        epochs=50,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    print(\"\\nTesting the model with sample inputs...\")\n",
        "    test_inputs = [\n",
        "        \"I've been feeling really sad lately\",\n",
        "        \"I'm having trouble sleeping\",\n",
        "        \"I feel anxious all the time\"\n",
        "    ]\n",
        "\n",
        "    for test_input in test_inputs:\n",
        "        response = model.generate_response(test_input, data_preparator.tokenizer)\n",
        "        print(f\"\\nInput: {test_input}\")\n",
        "        print(f\"Response: {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Mental Health LLM training...\")\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f8150fb33874a928be3320b4bc8612b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69b51a6a317e4d10aff10e1c1e154134",
            "placeholder": "​",
            "style": "IPY_MODEL_1278b93fbf9b43cf9eab317eb70ccd60",
            "value": "adapter_config.json: 100%"
          }
        },
        "1278b93fbf9b43cf9eab317eb70ccd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59ccacd60ffb429ba840615b79e7c155": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "645ddd6da38d4687914a06598b84b917": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69b51a6a317e4d10aff10e1c1e154134": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9701fe6fd7b74b51bfee42055a2d5098": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f8150fb33874a928be3320b4bc8612b",
              "IPY_MODEL_dc49e9a469684be7800ea543221ce22f",
              "IPY_MODEL_ba6bab2622774c9da7fed24d4886a8a9"
            ],
            "layout": "IPY_MODEL_645ddd6da38d4687914a06598b84b917"
          }
        },
        "b4e45d5a30a54fd99aa994a451da5851": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9fd4a6fe9e84b21b6dd2a060949d948": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba6bab2622774c9da7fed24d4886a8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59ccacd60ffb429ba840615b79e7c155",
            "placeholder": "​",
            "style": "IPY_MODEL_b4e45d5a30a54fd99aa994a451da5851",
            "value": " 587/587 [00:00&lt;00:00, 11.7kB/s]"
          }
        },
        "c91d80f31ffa41f5864bfbcf9a0936b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc49e9a469684be7800ea543221ce22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c91d80f31ffa41f5864bfbcf9a0936b1",
            "max": 587,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9fd4a6fe9e84b21b6dd2a060949d948",
            "value": 587
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
